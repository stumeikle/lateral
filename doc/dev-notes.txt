20161119

A note about sequences.
Its normal enough to use db sequences to assign ids when writing to the db.
Ids are not present until the object is persisted. Fine. We'd annotate entities with lines like:

@GeneratedValue(strategy=GenerationType.AUTO)
@SequenceGenerator(name="my_seq",sequenceName="MY_SEQ", allocationSize=1)

We'd expect with Lateral, when write-through is enabled, that the usual handling of sequences would
occur.

This is not the case. Alas we need to pass new entities to our cache layer _before_ they are
write-through en to the db, and in the case of hazelcast at least, we can't pass in an object
with no sequence. So the sequence aspects are tied to the choice of cache.

I'll set things up to allow objects with null ids to be passed through to the cache layer, in
case another cache is used which allows the write-through to happen before the id is populated
and the object stored in the case.

For the hazelcast case i'll need to enable the plugin or generator to be configured to support
sequencing on particular fields. this has some other consequences -- hc ids are longs but we may
expect or specify other types in our proto. the domain is being affected by the choice of
cache layer. :(
This is very interesting in relation also: https://github.com/hazelcast/hazelcast/issues/11
it really is much better to just use guids
[NEW FEATURE - support generated int ids]
  [info: generators might go into default factory impl. need to set start value tho]

[BUG] [Done]
if I set @RepositoryId on a primitive field in my proto then compilation fails. but it shouldn't.
The generator needs to be fixed to swap types if the user specifies @RepositoryId on a primitive.

[BUG] [Done]

or feature. if i call create through the REST API i do need to get the created objec id back.
even if its generated by a cache layer sequence

[FEATURE, ISSUE]

did I ever check the dbdumpers function properly or at all in failover mode?

[BUG] [done]

HC repository impls have parmeter names with capitals


20161119 Sequences again

.. are hard. Whether write-through or write-behind, if the system is restarted the next sequence id needs to
come from the db. this means the whole system needs to wait on the db processes being up first. in the case
of write-behind, the db might not even be up to date. it could be that the queue is still being written to the
db.

so the cache layer can't be initialised until the db is up.hmm

in the case of write-behind we were going to have a system which injected the current set of objects from the db
into the caches. (oi like). this process could also inject the sequence initiation values. how does that work in
the write-through case? and how would the other components know to wait on the oi process?

for HC. the map store class on the server attempts to load all keys on startup. we could hook into that.
we might need a concept of 'com'. if h/c goes down (chance=?) and the dbdumper is an hour behind we won't want
to wait an hour to restart. so we'd need a way to correctly repopulate the cache. how to do that.
current HC is tied into that throught he mapstore. maybe we should use a file store to back up the cache for the
write behind case. though thats not ideal.

Next job:
sort out the admin bus.
then use it to only allow access to the cache when the cache has been correctly populated at startup
do this in both write-behind and write-through cases
then use these mechanisms to support generated sequences
and then finally ensure that clients get their id values back when creating

No access to cache if cache not initialised
no writing to cache if dbdumper process not up (or equivalent with write-through)
so we use the maps and the admin repository
we don't want the admin cache to be persisted, btw
if the users have configured no persistence for the cache then just proceed as usual
consider write-through with multiple servers. even if we use the map store to load the cache the secondardy
client needs to know to wait before they use the cache. maybe hazelcast does that for us. this is cache by cache
loading also, which might be nice
maybe we just hook into the mapstore then

20161121

mapstore ok but for write behind, mapstore would need to send admin command to db dumpers to populate the cache.
and that's a whole mechansim missing. ie command send, command receive, do we say only 1 db dumper should handle?
how do we lock, how do we ensure only one responds, what if that system crashes before the cache loaded, etc

20161122

Think we'll do... send command to admin bus. use optimistic locking to allow only 1 dbd to receive command.
dbd goes and does its stuff. if it fails for any reason, use manual means to resend the admin command.
once its done it can set the cache loaded flag. Q: how do we get events back to the clients? a broadcast event
would be good. can entities watch for changes on a given map entry in an adhoc manner? not very easily it looks
like ... http://docs.hazelcast.org/docs/3.5/manual/html/map-maplistener.html
might as well poll as create such a structure. though maybe everything could listen for events on the admin bus

[BUGs, GAPs x 1000000] db dumper functionality is very sketchy. no file buffer. unclear if active-pass supported yet

[MISSING FEATURE ... client apps should be able to select which of the distributed caches that they connect to
there's no need for them to connect to them all]

20161127

Getting on with it.
(Loading of the caches on startup)
All good. Now we have a slight change of things though. previously we only had mapstores
for the write-through case. Now we'll have map stores in all cases, and use that in the
write-behind case to manage the loading of the caches (sending commands to the remote db
dumpers). that's fine. in the write behind case though we'll need to skip the other
methods. So, mapstore functionality differs between write-though and write-behind quite
a bit more substantially

20161128

Single system. Write through. Ideally synchronous writes. Non synchronous writes rely on hz cache being up else
data loss will occur. Additionally using mapstore to perform the writes means updates to object may be missed and
can't be guaranteed to be persisted. User should be able to configure load from db and initial load from db

Write behind. Currently dbd listens to the bus to ensure that all updates can be audited and all changes persisted to
db. I think thats fine. We don't need additional mapstore communications overhead if we have a busy system. we know
the changes already. it allows us to split dbds by cache and so on too. but then we need to send a command to populate
the caches initially and to decide if the user wants individual loads from db too. we need to go via dbd because the
updates may not have been persisted to db yet and only dbd has enough info to know the current state
in this case load, loadAllKeys, will go to dbd and store will do nothing (in the mapstore). its a pity we can't split
the map store using the hc api. maybe we can. maploader. cooooool. loooks like we can either have a loader or a load
and store. but no store on its own.

user options: pick loader, storer, write their own
            : pick local or remote

if we have a plugin for loading a plugin for storing and plugins for remote connections that should cover it
then the mapstorefactory will just provide proxies to the plugins
mapstorefactory anyway is injected.

so. if write-through or read-through then install the mapstorefactory.
this proxies to the plugins
then plugin selection will change the behaviour from local to remote etc
might need to review if we need the persister and retriever classes after that
we could simply configure the mapstore factory implementation in the config and then
say if there -is- a config then install the mapstore factory

eg
        //di.class.for.HCMapStoreFactory=transgenic.lauterbrunnen.lateral.persist.hazelcast.generated.HCReadThroughFactoryImpl
        //di.class.for.HCMapStoreFactory=transgenic.lauterbrunnen.lateral.persist.hazelcast.generated.HCWriteThroughFactoryImpl
        //di.class.for.HCMapStoreFactory=transgenic.lauterbrunnen.lateral.persist.hazelcast.generated.HCReadWriteThroughFactoryImpl

the pluginfactories might need to be generated of course
hmm.
bit more twisty turny
maybe the plugins can specify the implementation

so. getting there.
hc embedded plugin checks for read-through or write-through config and if present installs our factory
the factory will use the config to then choose the read and/or write map store imps
and the read and/or write imps will then inject the persister and retriever

The map store factory can configure the injections for the write-through and read-through
although probably needs to defer to the config if there is any

Task for now: update the admin bus to allow returning results of commands

20161129

craeteing the remote retriever. next = create direct and remote persister [done]
update entities to have jpql for retrieving keys [done]
create the RT WT proxies [done]
fix the retrievers to convert repositoryids [done]

fix HCCacheChangeManagerImpl [done]

** Get to point where micro can save entries via rest, retrieve already known entries on startup
** delete entries etc
Insert test case here:

That still leaves dbdumper lacking but is enough for a git push
Then fix the bugs above, get sequences working etc.

17:45 mainly working now

20161130

[BUG] [FIXED] most probably the updateId used to ensure all updates are captured in write-behind is not correctly set after
startup. i imagine it reverts to 0 and needs to be set to the next correct value

[BUG][NAI] simple hazelcast example broken after the rest generation additions. [Correction -- not an issue]

[MISSING] even without file queue, dbdumper needs to be able to capture remote retrieve events and respond

[NOT OPTIMAL] if i want a hazelcast server with remote read (normal enough) i have to include a lot of guff.
split out the remote persist / retrieve into a separate generator
[ADDITIONAL] looks like generate persisters depends on generate entities and also on persistence.xml. again need to be able
to build the remote stuff without the local. the problem is that the 'direct' map stores go straight into the entities
. we could leave them out and then we'd need another geneartor for the map store factory without them in.
DO THIS NEXT. generate persisters with only remote and no entities. also make the change listener optional

[BUG] [fixed]
initial cache load causing problems with dbdumper
when the load is put into the cache the dbdumper tries to write the
entities to db again, violating primary keys

[BUG] [fixed]
has been persisted flag in impl does not appear to be used, or set properly
remove this flag. we can just check if the object is in the cache before applying an update
having a transitory field is anyway daft as it won't get into the cache or be distributed to the different nodes

[BUG BUG] [fixed. needed to use jgroups for bus]
major issues with hazelcast maps for admin messages. lots of odd behaviour and blocking
switching to broadcast messages. https://hazelcast.org/use-cases/messaging/
will have to be 2 way though and tested to death. doenst really need to be broadcast as its only between hz server
and dbdumpers

20161203

left in a mess. somehow the new admin bus has cross over between topics. messages going out on address (eg)
are coming back on head.crossover fixed but still random blocking. what is up with hazelcast

20161204 really struggling with this
topic publish blocks regardless of what i do.
maybe hazelcast can't handle publishing to topics from within a mapstore operation
not sure but its miserable. might use an alternative broadcaster to see if that fixes the issue


20161212

lots of thoughts around optimistic locking and sequences and what to support there.
optimistic locking is off in lateral so far. could enable it... might be a generator properties
could even use a blocking queue for sequs. anyway. i think the 'soft' sequences offered by hc
don't offer much. particularly if the system is restarted often

zzz . So the update id values. rubbish. or? with hc they won't sustain a restart of the system, unless
we add in some messiness. unique ids would be better. we * could * use an int/ long with optimistic locking
but i don't want to insist on that for every update.

options:
enforce optimistic locking on updates. i don't want to do that, some entities might be scratch
enough that it doesn't matter.
then we need a unique update id. can use guids but they are rather large tbh
can use the idgenerators but then we need to persist the end state or prefix with date or somesuch.
currently there is one idgen per repository. if update id stored i guess we could use that on map load.

20161213

but the reality is quite messy. the server side needs to establish the update value but the server side
doesn't really know about the repos. also it sets the map store in the config but the hazelcast instance is
needed if the map store is later to set the update id. really the map store should not know anything about hc
and the hc call map store stuff should be extended to also populate the initial ids.
Solution found using maploaderlifecyclesupport. All good.

Stuff to do now:
[a] extend retriever direct to pull in the last update id. [done]
    [a.1] will need a new jpql and query u[done]
[b] extend the admin endpoints to be able to support this remotely also
    which means a remote impl [done]
    and an endpoint [done]

[CHECK] do methods in map store need to be synchronized?

[FEATURE] next step is to add optimistic locking optionally in domain model. and then based on that we can
implement (finally) sequences. should optimistic locking be the default??
--> looking to implement now. gets into transactions though. .... need to think about that
[done]

[SEQUENCES] still on this thing. so. in order to store sequences we need a new map for storing them, and the related
entities. fine. we could then inject a hidden class into the prototypes. fine. but refactoring needed first:
[done] for now

[1] change the generators not to use the proto package except for step 1. (this would allow us to extend the proto
classes on the fly). (looks like cache and domain are ok in this regard) [done]

[LIMITATION] we'd need to check if we support subpackages within the domain prototype. i think probably not.
would need testing. perhaps will work so long as the entity names themselves are unique

[BUGS] almost there now with sequences. but. internal entities are not being created at the db. db entity names
have changed in the db, should not have _ENTITY on the end of them
almost done. I found a 'bug' in hazelcast though :( https://groups.google.com/forum/#!topic/hazelcast/Ji_g-DZwr7o
map store doesn't differentiate between put and udpate
[FIXED] worked around

Things to do stu: add to github comparison between lateral and spring boot.
different emphasis in lateral, domain is more isolated, domain objects do not need defining at the data level/entity level
unlike spring boot lateral supports write through and write behind

20170413
what to do next? could look at the search engine stuff. maybe looking at solandra would make sense. indeed could think
about schemaless storage of the data. maybe we shouldn't consider only rdbms. it should be in principle straight forward
to create new persisters which write to cassandra and perhaps don't use or need the entity classes.


20180531

Thoughts of future things to add: cassandra, solandra or similar, containerisation, what config model do we support?
Easy upgrade paths for db and hazelcast. schema changes etc.

20180909

Make the jar files executable.

20181118

Starting to get to the limits of generate-everything and lots-of-plugins. It becomes quite hard to do normal tasks
such as add in validations and so on. Everything needs to be propagated everywhere. Should we just use
generation to get things moving initially, rather than at every step of the way?

Options for validation:
add annotations to the domainLibrary classes. maybe reuse the existing entity validations
add annotations to the repository classes and stop the generation
add annotations to the entity classes and stop the generation there
add annotations, somehow, at the hazelcast level and stop the generation there
(or code).

change the domainLibrary to use classes which do the validation. would that even work given the framework?
perhaps lateral v1 has had it's day?

Experimenting with new types to encapsulate the validation.
It's a bit of a pain in the balls. IE need to swap types for the entities and then the rest loading fails.
SO maybe this isn't the way to go. maybe validations based on annotations are the way. special types are a pain
in the balls

Ok, it is possible to have a validated object type. its a little bit fiddly, you need changes to generate.properties
and changes to the class itself to support hashCode and Serialised and fromString etc. but then it does work.
not sure about the imports in the generated code though maybe that's a BUG

the other way to do this would be to use primitive types in the domain and put validation else where. but..
that's hard too.

[IMPROVEMENT] improve the generation mechanism so that the imports work for short named types used in the converter.

-> Update on the validated types. Doesn't work so well. Hazelcast search predicates etc rely on the type being mor
e basic. and that makes sense. we can't compare entries in the db if they are non primitive. So perhaps it
makes more sense to have primitive types and then validate elsewhere.

-------------------
[BUG] the put rest endpoints, if the respitory Id is a unique id, these attempt to retrieve using a string
instead of a uuid, which fails.

IE the Rest container uses a String to store the repository id and we can't just pass this into the Repository retrieve. We need to convert it back to a Unique ID first.

20190526-- Fixed
-------------------


20190527

Db dumpers. Not sure where we got to with this. It doesn't look to me today like the dbdumpers could run actve-active.
However, it would be straightforward enough to use a distributed queue with hazelcast and therefore store all changes
to the distributed store with the results being read and transferred to db then by n db dumper instances. should be fine
. we could even persist the store, but ... that's kind of the whole point of the dumper in the first place.

I'm curious about the performance of lateral. Untested as yet. Did I ever start to use Kryo?

[ISSUE] if I play with a broadcast bus setup I see that the application cannot be started until the dbdumper is running.
Is that an issue? It's blocking sending admin commands to get the latest updateId and hanging.

[BUG] seeing lots of cast problems in DB dumper when running with the example application. Something has changed since
I last run it up. (Lots of cast problems from Command to CommandResponse or vice-versa). It may just be responding to
it's own outgoing command response messages. but repeated pings to the application kills it.

20190528

Admin bus errors on db dumper. It all looks a bit of a mess in terms of how it's set up to be honest. Rationalising ...
How do we sort out the admin bus in the microservice case? That's unclear to me?

I think we wrongly differentiate between hazelcast embedded and server, muddled from the older misunderstanding still.

So in the microservice case, we use HCMapStoreRWT for example to set up the hazelcast map store. And that in turn sets
retrievers and persisters which operate on the direct local db so the admin bus is not needed at all.
Geez, supporting all this stuff really needs a tonne of test cases.

Ok, then in the broadcast bus case. Essentially each app, whether embedded or not, is the command sender side of the admin
bus. [FIX] the hazelcast server instance. So is that what we have?

Well the embedded hazelcast does create the needed queues and install a handler for the responses. I guess that kind of
makes sense. What happens on the dbdumper side? We have a chicken and egg thing. The dbdumper tries to connect to an
external hazelcast instance which doesn't exist.
    -> Really the choice of embedded or server based should be separate from the choice of command sender or command responder.
    [FIX]

Even the cache change listener is really a separate thing from an admin bus responder.

So, we have, plugins:
HazelcastEmbeddedPlugin -- the embedded hc connector
HazelcastPlugin -- the hc server connector
HazelcastCacheListenerPlugin -- really this is what listens to and perists changes heard in the cache. it is essentially
the db dumper. HazelcastCacheChangePersisterPlugin

AdminCommandSenders will block until the AdminCommandResponders respond. That's probably not idea but there u are.
Not too clear to me why this is outwith hazelcast but there were notes above about that.

AdminCommandSender and AdminCommandResponder are completely separate from the cache implementation.
We could of course have multiple active responders. We'll have to figure out how we manage that. Team Titans hehe

... except they're not. We register the admin ... gosh so darn sophisticated.

HC Cache Change Manager registers all the domain classes with admin endpoints so that when we receive an admin command
relating to each entity we can respond to it. We can even retrieve the data locally or remotely. (Circular dependencies
might ensue). Though looks like we just use local.

So the cache change manager sets up the command handler to respond to incoming admin commands.
That seems wrong, why is it in the cache change manager ...
the cache change manager really sets up the cache changer persistence.
So it's true we could separate the cache change persistence from the admin bus responder.
even though in this case they are bound to the db peristence function

Going to be fiddly due to the generation.
Steps?
(1) remove the admin command bits from the plugins
    -> kind of can't do this because the cache change plugin is bound to the admin responder for now .
(2) put them in new plugins
(3) rename the old plugins

that should be enough to get db dumper working again
then
(4) rename the hccachechangemanager and split out the admin endpoint initialisation
(4.5) remove the endpoint initialisation from the generated cache change manager
(5) update all the generators and the archetypes


Implementation notes: we might want to go even further. Basically we should be able to set an admin responder in any
app that could respond to any particular admin command. like thread dump, do this, do that. Fine.
So the admin commands we install to respond to cache initialisation, are very specific commands .

^^ need more thought. where do these commands originate ? in the remote retriever etc. so the retrieve says, the db is
remote, i'll send an admin command to retrieve the object or keys. fine. this is good, it's really ADMIN. Perhaps if
we want individual apps to have commands we can call these non-admin. but that's for later.
For now admin command responder is the one that will respond to these messages.
 (1), (2) complete.

Next task -- test the dbdumper with manually changed config and the application.
started this but null pointers on the sender side . TODO

[BUG] as part of the hazelcast embedded start up we initialise the mapstore. The mapstore makes a jgroups broadcast
call to the dbdumper to retrieve parameters such as last update Id. somehow this is causing a timeout in the hazelcast
initialisation code. So i've no idea how this worked in the past.

This means the HCMapStoreRT and other classes should not call retriever in the initialisation method. :( boohttps://uk.search.yahoo.com/yhs/search;_ylt=AwrIS.gIcu5clBUA3xN3Bwx.?p=roof+window&fr2=sb-top&hspart=ddc&hsimp=yhs-linuxmint&type=__alt__ddc_linuxmint_com`
The retriever will need to be called later in the update cycle. But of course before the application itself properly
starts. What a drag. We could move this to the repository manager perhaps. So this is growing arms and legs.

[BUG] do we have topics littered in there that we no longer use? I think they had the same problem tbh that the broadcast
bus is having now. Could be, so perhaps if we can resolve this we can revert back to using topics.
WHAT A PALAVA

Ok, i'll comment out the retrieval during the map store init and see if that fixes start up TEMPORARY
-> Yes that works fine. So I need to kick off the process after the hazelcast initialisation.

Getting too confusing for me.

Bug QUESTION. The only place the cache and the update ids can come from is the db dumper. so why not just let it populate
the cache once and for all? I suppose the answer is that different clients might need different content so why not let
them pull it as they need to. < I would hope hazelcast won't ask multiple times for the same context in the map store
impls >

It seems a pretty shit design from hazelcast that the mapstore initialisation operates in this way.

Could we just ditch the map store altogether? Just use the dumper to persist and let the app send commands to the
dumper to populate the caches in the first place?

That would be fine. The only problems here are my crazy attachment to doing everything in one framework.

Needs to be a lot simpler.
Requirements
(1) there is sometimes a need to capture all updates and reflect these to the db. even if that happens slower than real time
(2) there is sometimes a need to restore from the db. clients might not know what they need (eg all orders) but should
be able to filter out what they don't need.
(3) ideally we can support micro services as well as broadcast buses.

Think we need to do some experiments

EG 2 hc embedded apps. 1 db dumper thing. let the db dumper and apps start at different times. then load the context from
the dbdumper side. do the apps see the objects being loaded? what about the update id? that's kind of more significant
how will the apps know if the update id has been set?

In this case we'd not need an admin bus
and the mapstore would only perhaps be relevant for the micro service case.

