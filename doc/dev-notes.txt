20161119

A note about sequences.
Its normal enough to use db sequences to assign ids when writing to the db.
Ids are not present until the object is persisted. Fine. We'd annotate entities with lines like:

@GeneratedValue(strategy=GenerationType.AUTO)
@SequenceGenerator(name="my_seq",sequenceName="MY_SEQ", allocationSize=1)

We'd expect with Lateral, when write-through is enabled, that the usual handling of sequences would
occur.

This is not the case. Alas we need to pass new entities to our cache layer _before_ they are
write-through en to the db, and in the case of hazelcast at least, we can't pass in an object
with no sequence. So the sequence aspects are tied to the choice of cache.

I'll set things up to allow objects with null ids to be passed through to the cache layer, in
case another cache is used which allows the write-through to happen before the id is populated
and the object stored in the case.

For the hazelcast case i'll need to enable the plugin or generator to be configured to support
sequencing on particular fields. this has some other consequences -- hc ids are longs but we may
expect or specify other types in our proto. the domain is being affected by the choice of
cache layer. :(
This is very interesting in relation also: https://github.com/hazelcast/hazelcast/issues/11
it really is much better to just use guids
[NEW FEATURE - support generated int ids]
  [info: generators might go into default factory impl. need to set start value tho]

[BUG] [Done]
if I set @RepositoryId on a primitive field in my proto then compilation fails. but it shouldn't.
The generator needs to be fixed to swap types if the user specifies @RepositoryId on a primitive.

[BUG] [Done]

or feature. if i call create through the REST API i do need to get the created objec id back.
even if its generated by a cache layer sequence

[FEATURE, ISSUE]

did I ever check the dbdumpers function properly or at all in failover mode?

[BUG] [done]

HC repository impls have parmeter names with capitals


20161119 Sequences again

.. are hard. Whether write-through or write-behind, if the system is restarted the next sequence id needs to
come from the db. this means the whole system needs to wait on the db processes being up first. in the case
of write-behind, the db might not even be up to date. it could be that the queue is still being written to the
db.

so the cache layer can't be initialised until the db is up.hmm

in the case of write-behind we were going to have a system which injected the current set of objects from the db
into the caches. (oi like). this process could also inject the sequence initiation values. how does that work in
the write-through case? and how would the other components know to wait on the oi process?

for HC. the map store class on the server attempts to load all keys on startup. we could hook into that.
we might need a concept of 'com'. if h/c goes down (chance=?) and the dbdumper is an hour behind we won't want
to wait an hour to restart. so we'd need a way to correctly repopulate the cache. how to do that.
current HC is tied into that throught he mapstore. maybe we should use a file store to back up the cache for the
write behind case. though thats not ideal.

Next job:
sort out the admin bus.
then use it to only allow access to the cache when the cache has been correctly populated at startup
do this in both write-behind and write-through cases
then use these mechanisms to support generated sequences
and then finally ensure that clients get their id values back when creating

No access to cache if cache not initialised
no writing to cache if dbdumper process not up (or equivalent with write-through)
so we use the maps and the admin repository
we don't want the admin cache to be persisted, btw
if the users have configured no persistence for the cache then just proceed as usual
consider write-through with multiple servers. even if we use the map store to load the cache the secondardy
client needs to know to wait before they use the cache. maybe hazelcast does that for us. this is cache by cache
loading also, which might be nice
maybe we just hook into the mapstore then

20161121

mapstore ok but for write behind, mapstore would need to send admin command to db dumpers to populate the cache.
and that's a whole mechansim missing. ie command send, command receive, do we say only 1 db dumper should handle?
how do we lock, how do we ensure only one responds, what if that system crashes before the cache loaded, etc

20161122

Think we'll do... send command to admin bus. use optimistic locking to allow only 1 dbd to receive command.
dbd goes and does its stuff. if it fails for any reason, use manual means to resend the admin command.
once its done it can set the cache loaded flag. Q: how do we get events back to the clients? a broadcast event
would be good. can entities watch for changes on a given map entry in an adhoc manner? not very easily it looks
like ... http://docs.hazelcast.org/docs/3.5/manual/html/map-maplistener.html
might as well poll as create such a structure. though maybe everything could listen for events on the admin bus

[BUGs, GAPs x 1000000] db dumper functionality is very sketchy. no file buffer. unclear if active-pass supported yet

[MISSING FEATURE ... client apps should be able to select which of the distributed caches that they connect to
there's no need for them to connect to them all]

20161127

Getting on with it.
(Loading of the caches on startup)
All good. Now we have a slight change of things though. previously we only had mapstores
for the write-through case. Now we'll have map stores in all cases, and use that in the
write-behind case to manage the loading of the caches (sending commands to the remote db
dumpers). that's fine. in the write behind case though we'll need to skip the other
methods. So, mapstore functionality differs between write-though and write-behind quite
a bit more substantially

20161128

Single system. Write through. Ideally synchronous writes. Non synchronous writes rely on hz cache being up else
data loss will occur. Additionally using mapstore to perform the writes means updates to object may be missed and
can't be guaranteed to be persisted. User should be able to configure load from db and initial load from db

Write behind. Currently dbd listens to the bus to ensure that all updates can be audited and all changes persisted to
db. I think thats fine. We don't need additional mapstore communications overhead if we have a busy system. we know
the changes already. it allows us to split dbds by cache and so on too. but then we need to send a command to populate
the caches initially and to decide if the user wants individual loads from db too. we need to go via dbd because the
updates may not have been persisted to db yet and only dbd has enough info to know the current state
in this case load, loadAllKeys, will go to dbd and store will do nothing (in the mapstore). its a pity we can't split
the map store using the hc api. maybe we can. maploader. cooooool. loooks like we can either have a loader or a load
and store. but no store on its own.

user options: pick loader, storer, write their own
            : pick local or remote

if we have a plugin for loading a plugin for storing and plugins for remote connections that should cover it
then the mapstorefactory will just provide proxies to the plugins
mapstorefactory anyway is injected.

so. if write-through or read-through then install the mapstorefactory.
this proxies to the plugins
then plugin selection will change the behaviour from local to remote etc
might need to review if we need the persister and retriever classes after that
we could simply configure the mapstore factory implementation in the config and then
say if there -is- a config then install the mapstore factory

eg
        //di.class.for.HCMapStoreFactory=transgenic.lauterbrunnen.lateral.persist.hazelcast.generated.HCReadThroughFactoryImpl
        //di.class.for.HCMapStoreFactory=transgenic.lauterbrunnen.lateral.persist.hazelcast.generated.HCWriteThroughFactoryImpl
        //di.class.for.HCMapStoreFactory=transgenic.lauterbrunnen.lateral.persist.hazelcast.generated.HCReadWriteThroughFactoryImpl

the pluginfactories might need to be generated of course
hmm.
bit more twisty turny
maybe the plugins can specify the implementation

so. getting there.
hc embedded plugin checks for read-through or write-through config and if present installs our factory
the factory will use the config to then choose the read and/or write map store imps
and the read and/or write imps will then inject the persister and retriever

The map store factory can configure the injections for the write-through and read-through
although probably needs to defer to the config if there is any

Task for now: update the admin bus to allow returning results of commands

20161129

craeteing the remote retriever. next = create direct and remote persister [done]
update entities to have jpql for retrieving keys [done]
create the RT WT proxies [done]
fix the retrievers to convert repositoryids [done]

fix HCCacheChangeManagerImpl [done]

** Get to point where micro can save entries via rest, retrieve already known entries on startup
** delete entries etc
Insert test case here:

That still leaves dbdumper lacking but is enough for a git push
Then fix the bugs above, get sequences working etc.

17:45 mainly working now

20161130

[BUG] [FIXED] most probably the updateId used to ensure all updates are captured in write-behind is not correctly set after
startup. i imagine it reverts to 0 and needs to be set to the next correct value

[BUG][NAI] simple hazelcast example broken after the rest generation additions. [Correction -- not an issue]

[MISSING] even without file queue, dbdumper needs to be able to capture remote retrieve events and respond

[NOT OPTIMAL] if i want a hazelcast server with remote read (normal enough) i have to include a lot of guff.
split out the remote persist / retrieve into a separate generator
[ADDITIONAL] looks like generate persisters depends on generate entities and also on persistence.xml. again need to be able
to build the remote stuff without the local. the problem is that the 'direct' map stores go straight into the entities
. we could leave them out and then we'd need another geneartor for the map store factory without them in.
DO THIS NEXT. generate persisters with only remote and no entities. also make the change listener optional

[BUG] [fixed]
initial cache load causing problems with dbdumper
when the load is put into the cache the dbdumper tries to write the
entities to db again, violating primary keys

[BUG] [fixed]
has been persisted flag in impl does not appear to be used, or set properly
remove this flag. we can just check if the object is in the cache before applying an update
having a transitory field is anyway daft as it won't get into the cache or be distributed to the different nodes

[BUG BUG] [fixed. needed to use jgroups for bus]
major issues with hazelcast maps for admin messages. lots of odd behaviour and blocking
switching to broadcast messages. https://hazelcast.org/use-cases/messaging/
will have to be 2 way though and tested to death. doenst really need to be broadcast as its only between hz server
and dbdumpers

20161203

left in a mess. somehow the new admin bus has cross over between topics. messages going out on address (eg)
are coming back on head.crossover fixed but still random blocking. what is up with hazelcast

20161204 really struggling with this
topic publish blocks regardless of what i do.
maybe hazelcast can't handle publishing to topics from within a mapstore operation
not sure but its miserable. might use an alternative broadcaster to see if that fixes the issue


20161212

lots of thoughts around optimistic locking and sequences and what to support there.
optimistic locking is off in lateral so far. could enable it... might be a generator properties
could even use a blocking queue for sequs. anyway. i think the 'soft' sequences offered by hc
don't offer much. particularly if the system is restarted often

zzz . So the update id values. rubbish. or? with hc they won't sustain a restart of the system, unless
we add in some messiness. unique ids would be better. we * could * use an int/ long with optimistic locking
but i don't want to insist on that for every update.

options:
enforce optimistic locking on updates. i don't want to do that, some entities might be scratch
enough that it doesn't matter.
then we need a unique update id. can use guids but they are rather large tbh
can use the idgenerators but then we need to persist the end state or prefix with date or somesuch.
currently there is one idgen per repository. if update id stored i guess we could use that on map load.

20161213

but the reality is quite messy. the server side needs to establish the update value but the server side
doesn't really know about the repos. also it sets the map store in the config but the hazelcast instance is
needed if the map store is later to set the update id. really the map store should not know anything about hc
and the hc call map store stuff should be extended to also populate the initial ids.
Solution found using maploaderlifecyclesupport. All good.

Stuff to do now:
[a] extend retriever direct to pull in the last update id. [done]
    [a.1] will need a new jpql and query [done]
[b] extend the admin endpoints to be able to support this remotely also
    which means a remote impl [done]
    and an endpoint [done]

[CHECK] do methods in map store need to be synchronized?